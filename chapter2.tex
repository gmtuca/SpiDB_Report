\chapter{Development}

This chapter describes the development of my database application, SpiDB, from September 2015 to March 2016, involving planning, testing and implemention. The project is open-source, which can be found at
\textit{https://github.com/SpiNNakerManchester/SpiNNakerGraphFrontEnd}.

By being part of the SpiNNaker team in Manchester, I was directly exposed to the ongoing research, frequently receiving feedback on my work. The collaboration was effectively bi-directional, as I was able to constantly find, evaluate and fix inconsistencies and bugs in the API not known to the team.

\section{Planning}
My project imposed a relatively steep learning curve, given the complexity of the low level distributed architecture, still under development. Given this, on the 5th? of September 2015, I attended the 5th? SpiNNaker workshop, where multiple researchers from around the globe gathered for a one week course on the basics of the hardware??. I was then officially introduced to the Manchester team... planning etc.

The plan involved splitting my project into two parts: building a NoSQL Key-value store and an SQL based Relational Database.

[blackboard is down...] get planning link

key-value then relational

\section{Requirements}

Large, commercial database management systems have a broad range of complex requirements. From these I have selected 4 important concepts which must have strict focus on the SpiDB system:

\begin{itemize}
	\item \textbf{Reliability}: user's queries must complete in a reasonable way. This means any internal errors, inconsistencies or communication failures should be handled from within the database system, avoiding unpredicted failures to the user. This is a difficult task given the unreliability of the SpiNNaker communication fabric, which is further discussed on XXXX.
	\item \textbf{Durability}: user's queries with the aim of modifying the database state should persist, being internally stored until removal. The SpiNNaker hardware does not contain permanent storage components, reducing this contraint to "insert operations must persist until shutdown". It would be possible to externally connect the board to a mass-storage device, but it is outside of the scope of this project.
	\item \textbf{Isolation}: executing transactions concurrently must have the same effect as doing so sequentially. Concurrency control is an important part of this parallel database system, as it aims to handle thousands of concurrent queries distributed among thousands of processing cores. An approach to ensure isolation in the system is further discussed in section \ref{sec:out-of-order}.
	\item \textbf{Scalability}: the system must be able to handle a large number of parallel queries and have enhanced performance when given more hardware resources, in this case processor count.	This is arguably the most important of all requirements, as the SpiNNaker team is currently focusing on building a large scale machine composed of 1,000,000 processing cores. If this application scales well, it will quickly be able to show the strengths and weaknesses of the machine.
\end{itemize}

These main requirements do not cover two of the four ACID (Atomicity, Consistency, Durability, Isolation) properties of a database: atomicity and consistency. Atomicity, althogh very important on a large commercial application, is extremely hard to achieve in a descentralized system, with the use of complex multi-core rollbacks, and falls out of the scope of this experimental project. Consistency is significant when ensuring data written to the database is valid according to constraints, triggers and cascades, which are originally non-existent in a reduced instruction data store and bring unecessary complexity given the aims of the project.

Lastly another outstanding requirement not implemented is a strong security protocol. Data encryption and authorization have many advantages, but present themselves as unecessary complexity for a small, private, experimental project.

\section{Technologies Used}
In this project I used mostly the SpiNNaker API, which is split into the Python toolchain, running on the host machine (user's computer) and C code, compiled into machine code to run on the board.
The full API can be found at \textit{https://github.com/SpiNNakerManchester}. A strong knowledge of ARM assembly was also needed, given the low level architecture.
 
These technologies were used to develop the following deliverables:
\begin{itemize}
	\item \textbf{Python}: (2000 lines of code) uploading binaries to the board, status checking, query parsing, Graphical User Interface, data analytics and socket communication.
	\item \textbf{C}: (2500 lines of code) event driven communication between processors, low level memory management, distributed query processing.
\end{itemize}

\section{Approach}

A tree structure composed of \textit{root}, \textit{branch} and \textit{leaf} nodes. The tree structure presented by my database management system allows a divide and conquer approach to the database query plan. This means when queries are issued by the \textit{host}[definition] and received at the \textit{root}, they are broken down and forwarded for parallel processing through \textit{branch} and \textit{leaf} nodes. eg. COUNT, MAX, MIN, AVG, SUM

problems:
sending a large amount of packets with little or no delay xx kills xx the core. sending more than about 4 packets symultaneously at a destination results on a very high packet loss (2/3 of SDP packets get dropped).


solutions:...
delays
tree structure
no acknowledgement


complexity


This approach has the following advantages (compared to a flat structure)
-a core will only ever receive packets from up to 4 other cores symultaneously (branch: 4, root: 1, leaf: 1), which is the limit of reliability.
-aggregation of results can be done in iterations/stages

disadvantage:
-less leaf nodes (which do the actual work)

LIMITATION:
no global timer, the maximum we can do is a timer for each chip (collection of 18 cores)
reliability

COMPLEXITY

limitation:
-single point of failure for each board(mention that it is already like that. no way to avoid).
-SDRAM bandwidth

scalability

message id and all other fields, etc.

each chip, following instances:...

\begin{itemize}
\item 1x \textit{sark} - monitor process provided by the API to handle low level SpiNNaker operating system functions
\item 1x \textit{reinjector} - utility process provided by the API to allow automatic re-propagation of dropped multicast packets
\item 1x \textit{root} - central node which handles direct communication with host machine via UDP and redirects incomming queries to respective cores. 
\item 3x \textit{branch} - intermediate node which aggregates queries from 4 leaf nodes and communicates back to host via UDP (why 4? because 4 sdp channels?). 
\item 12x \textit{leaf} - receives insert/retrieve queries from the root, processes the request and then returns result to branch node
\end{itemize}
why branches, etc?

%\includegraphics[width=0.8\textwidth, natwidth=794, natheight=1123]{images/spiDB_architecture.png}

\section{Key-value Store}
The first half of the project involved developing a distributed key-value store, in which users can insert and retrieve data entries in a dictionary form. This means the user must be able to set keys mapping to values and then retrieve such values when given the same keys, these can be of type \textit{int} or \textit{string}. This section describes in detail the internal processing of the insert (\textit{put}) and retrieve (\textit{pull}) queries. 

\subsection{PUT}
The \textit{put} operation is the main way of inserting data onto the SpiDB distributed database. 
Upon completion, such operation will store the specified key, mapping to its value, on the memory of an arbitrary chip in the Spinnaker board (as chosen by the \textit{root} core). This operation expects an acknowledgement from the core which stored the entry.

Example usage:
\begin{lstlisting}
put "hello" "world"
put 123 "foo"
put "life" 42
put 1 2
\end{lstlisting}
 
Internally the following steps occur:
\begin{enumerate}
\item User issues query of format \textit{put "key" "value"} on host machine.
\item Query and metadata are converted into a byte array with the following format, transferred via UDP over Ethernet to the board (figure \ref{fig:host-root}).
\lstinputlisting[language=C]{code/putQuery.c}
In this case \textit{SpiDBCommands} is set to the constant representing the put operation, \textit{id} identifies every query uniquely, \textit{info} contains bit encoding of the size and type of both key and value, \textit{k\textunderscore v} contains both entries appended.
\item Packet arrival triggers interrupt on \textit{root} core, via the SDP protocol, and is decoded.
\item \textit{root} selects a \textit{leaf} core to store the data entries in one of the following ways, specified by the user:
\begin{itemize}
	\item \textbf{Naive}: As packets arrive, they are assigned to a different \textit{leaf} node in a Round-Robin manner.
	\item \textbf{Hashing}: the given key is used to produce a 32-bit hash value, which is decoded to assign the query to a specific \textit{leaf} node.
\end{itemize}
\item \textit{root} communicates to chosen \textit{leaf} node with \textit{put} contents via SDP (figure \ref{fig:root-leaf}).
\item \textit{leaf} node triggers an interrupt and stores key-value entry into its dedicated region of SDRAM.
\item \textit{leaf} sends an acknowledgement message over UDP back to host (figure \ref{fig:leaf-host}).
\item User receives timing information and query result.
\end{enumerate}


Complexity: linear to the size of the input key-value, constant to database size.

\begin{figure}
\centering
\begin{minipage}{.32\textwidth}
  \centering
  \includegraphics[width=1\linewidth, natwidth=794, natheight=1123]{images/put1.png}
  \captionof{figure}{Host to root packet}
  \label{fig:host-root}
\end{minipage}%
\begin{minipage}{.32\textwidth}
  \centering
  \includegraphics[width=1\linewidth, natwidth=794, natheight=1123]{images/put2.png}
  \captionof{figure}{Root to leaf packet}
  \label{fig:root-leaf}
\end{minipage}
\begin{minipage}{.32\textwidth}
  \centering
  \includegraphics[width=1\linewidth, natwidth=794, natheight=1123]{images/put3.png}
  \captionof{figure}{Leaf to host packet}
  \label{fig:leaf-host}
\end{minipage}
\end{figure}


\subsection{PULL}


design decision: pull no reply....

 Syntax:
 \noindent
 {\large\textbf{pull} \textit{(int|string)}:key}\\\\
 
The \textbf{pull} operation is the main way of retrieving data from the SpiDB distributed database.
When the operation is issued, the SpiNNaker cores will be coordinated to search for the given key and, if found, the value mapped by it will be returned to host. If the key does not exist, no reply is given, resulting on a timeout on the host (reason for this...). This means 
-disadvantage: expensive if not found
-advantage: less packet drops as less internal communication traffic
 
\noindent
 Example usage:\\
 \begin{lstlisting}
 pull "hello"
 pull 123
 \end{lstlisting}
 Assuming successful execution of the put commands above, such pulls would return "world" and "foo" respectively.\\\\
 Complexity: linear to the size of the input, linear to database size.\\\\

\begin{enumerate}
\item User issues query of format \textit{pull "key"} on host machine
\item Query and metadata are converted into a byte array, transferred over UDP socket to board
\item Packet transfer triggers interrupt on \textit{root} core, which issues a \textit{multicast} packet to all \textit{leaf} nodes requesting them to search for occurences of "key"
\item \textit{leaf} triggers an interrupt
\begin{itemize}
\item If a \textit{leaf} node identifies "key" by scanning linearly through SDRAM, it responds to host (branch...?) with mapped value
\item Else no response is sent, yielding timeout on host (reason for this!!!...?)
\end{itemize}
\end{enumerate}


(benchmarking in chapter 3)
how the data is actually stored?

SQL:
column based?

bandwidth (max) vs throughput (actual)


identifies
flow control of:
put
pull
etc.

Upon completion of the project, 


\section{Relational Database}

\subsection{CREATE }
\noindent 
  {\large\textbf{CREATE TABLE} \textit{(string)}:tableName(\\
  	\textit{(string)}:column1 integer|varchar(\textit{int}),\\
  	\textit{(string)}:column2 integer|varchar(\textit{int}),\\
  	...\\
  	);}\\\\
\noindent
  Reserves memory space for an SQL table and stores its metadata. This operation expects an acknowledgement.\\\\
   Complexity: linear to the size of the input, constant to database size.\\\\
   
\subsection{INSERT}   
   
 \noindent
  {\large\textbf{INSERT INTO} \textit{(string)}:tableName(\textit{(string)}:column1,\textit{(string)}:column2,...)\\
  \textbf{VALUES}(\textit{(int|string)}:value1,\textit{(int|string)}:value2,...);}\\\\
\noindent
  Inserts specified values on the given table's memory space at an arbitrary chip. This operation expects an acknowledgement.\\\\
\noindent
   Complexity: linear to the size of the input, constant to database size.\\\\

\subsection{SELECT}   
   
\noindent
  {\large\textbf{SELECT} *|\textit{(string)}:column1,\textit{(string)}:column2,...\\
  \textbf{FROM} \textit{(string)}:tableName\\
  \textbf{WHERE} \textit{(string)}:column|\textit{(int|string)}literal \\=|!=|\textless |\textless =|
  \textgreater | \textgreater = \textit{(string)}:column|\textit{(int|string)}literal;}\\\\
\noindent
  Retrieves a list of entries corresponding to the previously inserted values on given table which match the WHERE criteria. Matching results are streamed in until timeout is reached. If no value matches the criteria, the Spinnaker board will not respond.\\\\
\noindent
Complexity: linear to the size of the input, linear to database size.\\\\
  
\section{User Interface} 

graphs from ui and ui itself 
  
\section{Out-of-order execution}
\label{sec:out-of-order}
As SpiNNaker is a distributed architecture, it may cause many issues and inconsistencies.
For example, if we try to execute the following code sequence in order:\\
\begin{lstlisting}[caption={Non-blocking execution}, label=list:non-blocking]
put "hello" "world"
pull "hello"
\end{lstlisting}

We are not guaranteed that the \textit{pull} query will retrieve the value "world". As both queries are executed symultaneously on the SpiNNaker board, there is a chance that the \textit{pull} operation will terminate before the \textit{put} does, thus failing to return a value.

As a solution to this dependency constraint, my SpiDB database API includes the syntax symbol "." (dot) which blocks execution until all preceeding operations terminate. This allows the programmer to control execution flow, choosing what is allowed to compute out-of-order (in parallel) and what should be sequentialised at a cost of performance. This is a similar concept to the Verilog blocking and non-blocking assignments.[?]

\begin{lstlisting}[caption={Blocking execution}, label=list:blocking1]
put "hello" "world"
.
pull "hello"
\end{lstlisting}

The above code will assure sequential code, meaning the \textit{pull} operation will always return "world". It is usually a good idea to block execution when given a dependency constraint. This can also be done with larger code fragments.

\begin{lstlisting}[caption={Blocking execution}, label=list:blocking2]
put "hello" "world"
put "life" 42
put 123 456
.
pull "hello"
pull "life"
pull 123
\end{lstlisting}

It is worth noting that although non-block operations can cause out-of-order execution, it does not occur very frequently. This is because, when transmitting data to the board, queries are serialised over ethernet in order of appearence and in addition there is a small forced transmission delay between these packets. This will be further discussed on chapter 3.%\autoref{cha:eval}.

\section{Testing and Debugging}
I started the project with a Test-Driven Development approach, writing Python tests with the \textit{unittest} module and C assertions with part of the SpiNNaker API module \textit{debug.h} and my own code. This allowed high reliability from the start.

Realtime debugging on the SpiNNaker board is relatively hard, but luckly the API provides ways to log messages in each core's private data memory, which can be read by an external process upon execution of the program. Debugging was performed with a tool named \textit{ybug}, also developed by the team, which allows core status checking, uploading binaries, reading logs and memory content, among other functionality.\cite{ybug} [link]

\begin{figure}
  \centering
  \includegraphics[width=1.3\linewidth, natwidth=1366, natheight=768]{images/debugging.png}
  \captionof{figure}{Debugging}
  \label{fig:debugging}
  \centering
  \includegraphics[width=1.3\linewidth, natwidth=1366, natheight=768]{images/testing.png}
  \captionof{figure}{Testing}
  \label{fig:testing}
\end{figure}


\section{Bugs}
I have been one of the few users of a large amount of the SpiNNaker API, currently under contruction. This means some of it has not been fully tested, resulting in strange behaviour at times, making debugging of my own application difficult.

blah blah test usability
particularly

Although not being directly part of the project, 

MENTORING

\begin{itemize}
\item \textbf{Duplicate packets:} when multiple distinct SDP packets were sent from different sources to the same destination, strangely the receiving core would read the same packet duplicated a number of times. This behaviour was unexpected, so upon extensive testing and collaboration from the team, I was able to point the issue to a running processor binary named \textit{reinjector} and resolve the issue. 

\item \textbf{Data Specification Error:} when uploading binaries to the board, sometimes cores would crash with the SWERR state. After giving the team detailed feedback on the issue, this was found to be caused by the SpiNNaker Data Specification framework, which handles allocation of data in shared RAM.

\item algorithms

\end{itemize}

From planning, design, testing, development, code review, etc. presentation of results to members of the Spinnaker team

It outlines also my approach and design choices with their advantages/disadvantages with the hardware and specification. (eg. no acknowledgements)
Approval from members of the SpiNNaker team.

Strengths and weaknesses (limitations) of spinnaker
...
Thomas, etc.
tutoring! kind of did it really

...upload different programs to run on each core.
Thus each chip contains the following instances: 

Bizantine protocol
